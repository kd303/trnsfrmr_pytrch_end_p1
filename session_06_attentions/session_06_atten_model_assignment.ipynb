{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "session_06_atten_model_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1B7zPPS8PvYd8zsaYxIhonRzDjfFxj2-e",
      "authorship_tag": "ABX9TyPtKtUydfPcsDqFjoC+2p9u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kd303/trnsfrmr_pytrch_end_p1/blob/main/session_06_attentions/session_06_atten_model_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdGm5D9YfX4_"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vfU3-RpfpoP",
        "outputId": "68b11264-0170-457a-ca82-6c883f7ed85e"
      },
      "source": [
        "drive.mount('/content/data')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eMNfuMxgI-A",
        "outputId": "9931722c-e71c-4269-9439-cb18a23b7480"
      },
      "source": [
        "cd /content/data/MyDrive/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xx8AGJPgKly",
        "outputId": "0611a67e-0208-4671-b2e0-12b6a0860469"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AMnDd0tgXE_",
        "outputId": "619fd543-9d2f-4a1e-8e52-4b489f3e0381"
      },
      "source": [
        "cd sample_data/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tqNQHcohLj9"
      },
      "source": [
        "!mkdir ses_6_data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVU1K9wThXYj",
        "outputId": "bb767ee3-d2e7-4516-d6e2-a3f285492613"
      },
      "source": [
        "cd ses_6_data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/MyDrive/ses_6_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9wE2YS3hYuC",
        "outputId": "7293e566-6b6f-493a-85c2-59a7e5d797ea"
      },
      "source": [
        "!wget http://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-27 17:48:55--  http://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8254496 (7.9M) [application/x-gzip]\n",
            "Saving to: ‘Question_Answer_Dataset_v1.2.tar.gz’\n",
            "\n",
            "Question_Answer_Dat 100%[===================>]   7.87M  2.02MB/s    in 4.9s    \n",
            "\n",
            "2021-11-27 17:49:00 (1.61 MB/s) - ‘Question_Answer_Dataset_v1.2.tar.gz’ saved [8254496/8254496]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkkh3fpVhqSk",
        "outputId": "e4ad168f-e61b-43f6-c5a0-259500b7d184"
      },
      "source": [
        "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-27 17:49:11--  http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
            "Resolving qim.fs.quoracdn.net (qim.fs.quoracdn.net)... 151.101.1.2, 151.101.65.2, 151.101.129.2, ...\n",
            "Connecting to qim.fs.quoracdn.net (qim.fs.quoracdn.net)|151.101.1.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58176133 (55M) [text/tab-separated-values]\n",
            "Saving to: ‘quora_duplicate_questions.tsv’\n",
            "\n",
            "quora_duplicate_que 100%[===================>]  55.48M  48.3MB/s    in 1.1s    \n",
            "\n",
            "2021-11-27 17:49:13 (48.3 MB/s) - ‘quora_duplicate_questions.tsv’ saved [58176133/58176133]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePxIy6XjhHrl"
      },
      "source": [
        "!tar -xvf Question_Answer_Dataset_v1.2.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvsVpUuE23IP"
      },
      "source": [
        "## !find /content/drive quora_duplicate_questions.tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEboGObth3cQ"
      },
      "source": [
        "## \n",
        "\n",
        "quora_data_file = '/content/drive/MyDrive/ses_6_data/quora_duplicate_questions.tsv'\n",
        "cmu_qna_file = '/content/drive/MyDrive/ses_6_data/Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt'\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgWhLUoycAIm"
      },
      "source": [
        "## Bit of my frustration and something you can ignore..\n",
        "\n",
        "Since My life has been spent in creating a word whcih is made of object, I cannot resist but creating classes and putting everything under a neat and tidy classes. Although I feel python is faking OOPs (that damn reference to self explicitly delcared in every memthod, compared to Java (old flame), I have accepted my fate :)\n",
        "\n",
        "#### Essentially two classes#\n",
        "1. ```language_dictonary``` - Sweetly ignoring DataLaoder and build_vocab for a custom built cluegy single threaded model.\n",
        "\n",
        "2. ```dataset_parser``` - Just a helper class loading TSV and dealing with dirty business."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMD9i3i-h9Fy"
      },
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "class dataset_parser:\n",
        "    def __init__(self, file_path, MAX_LEN):\n",
        "        self.file_path = file_path\n",
        "        self.MAX_LEN = MAX_LEN\n",
        "\n",
        "    def normalizeString(self, s):\n",
        "        s = self.unicodeToAscii(s.lower().strip())\n",
        "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "        return s\n",
        "\n",
        "\n",
        "    def is_max_length_match(self, p):\n",
        "        return (len(p[0].split(' ')) < self.MAX_LEN\n",
        "                and len(p[1].split(' ')) < self.MAX_LEN)\n",
        "\n",
        "    ## I found some characters which I dont understand, thou shall ignore those.\n",
        "    def unicodeToAscii(self, s):\n",
        "        return ''.join(\n",
        "            c for c in unicodedata.normalize('NFD', s)\n",
        "            if unicodedata.category(c) != 'Mn'\n",
        "        )\n",
        "\n",
        "    def filter_pairs(self, pairs):\n",
        "        return [p for p in pairs if self.is_max_length_match(p)]\n",
        "\n",
        "    def parseFile(self, file_type):\n",
        "        lines = open(self.file_path, encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "        # for Quora dataset, ignore rest of the columns\n",
        "        if file_type == 'QUORA':\n",
        "            pairs = [[self.normalizeString(l.split('\\t')[3]), self.normalizeString(l.split('\\t')[4])] for l in lines[1:] if len(l.split('\\t')) > 4]\n",
        "        else:  # CMU\n",
        "            pairs = [[self.normalizeString(l.split('\\t')[1]), self.normalizeString(l.split('\\t')[2])] for l in lines[1:] if len(l.split('\\t')) > 2]\n",
        "            # [pair for pair in pairs if len(pair[0].split(' ')) < MAX_LEN and len(pair[1].split(' ')) < MAX_LEN]\n",
        "        return self.filter_pairs(pairs)\n",
        "\n",
        "class language_dictionary:\n",
        "    def __init__(self, dataset_name, MAX_LEN):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_wrds = 2\n",
        "        self.MAX_LEN = MAX_LEN\n",
        "        self.dataset_name_ = dataset_name\n",
        "\n",
        "    @property\n",
        "    def dataset_name(self):\n",
        "        return self.dataset_name_\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_wrds\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_wrds] = word\n",
        "            self.n_wrds += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py2EoZcEzo1V"
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "quora = dataset_parser(quora_data_file, MAX_LENGTH)\n",
        "pairs = quora.parseFile('QUORA')\n",
        "\n",
        "input_sent = language_dictionary('QUORA_INPUT', MAX_LENGTH)\n",
        "output_sent = language_dictionary('QOURA_OUTPUT', MAX_LENGTH)\n",
        "\n",
        "for pair in pairs:\n",
        "    input_sent.addSentence(pair[0])\n",
        "    output_sent.addSentence(pair[1])\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixh7PhEljJc4"
      },
      "source": [
        "sample_input_sent = pairs[8379][0]\n",
        "sample_output_sent = pairs[8379][1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KoqRFDWjLiK",
        "outputId": "27481d37-ffad-4062-9a44-93e9faaafe70"
      },
      "source": [
        "sample_input_sent, sample_output_sent"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('where can adderalls be found in india without prescription and without adhd ?',\n",
              " 'can you get adderal without a prescription in india ?')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmgCPonusjTB"
      },
      "source": [
        "input_indices = [input_sent.word2index[word] for word in sample_input_sent.split(' ')]\n",
        "output_indices = [output_sent.word2index[word]  for word in sample_output_sent.split(' ')]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHEriZ75s6JQ",
        "outputId": "84f021e0-90ae-4508-c280-4150f2647ed9"
      },
      "source": [
        "input_indices,  output_indices"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([304, 23, 9352, 55, 4345, 10, 13, 289, 3765, 48, 289, 8064, 14],\n",
              " [27, 60, 305, 8955, 476, 56, 8956, 10, 435, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16LWzjDBt2z0"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "input_indices.append(EOS_token)\n",
        "output_indices.append(EOS_token)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WL1zniytPXf"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjQhb4YRtVu9",
        "outputId": "a091de33-ec41-412e-f0df-191a512f476c"
      },
      "source": [
        "device"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL8Z2tn-tZ6_"
      },
      "source": [
        "input_tensor = torch.tensor(input_indices, dtype=torch.long, device=device)\n",
        "ouput_tensor = torch.tensor(output_indices, dtype=torch.long, device=device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju6mWsgOaz27"
      },
      "source": [
        "## Variable understanding\n",
        "\n",
        "1. input_size = size of the vocabulary\n",
        "2. hidden_size = hiddent layer for embedding size\n",
        "3. hidden_ouput = out put dimension from LSTM/GRUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5kQo4XzupNh",
        "outputId": "fb4a90d1-4de8-432a-828c-b26a88d6f939"
      },
      "source": [
        "input_size = input_sent.n_wrds\n",
        "hidden_size = 256\n",
        "hidden_output = 128\n",
        "input_size"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53793"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfHz2100OJtE"
      },
      "source": [
        "## We will be faking a batch, here the embeddeing vector will be (vocab_size, hidden_size), what we really need is a batch (Vocab_size, batch_size, hidden_size)\n",
        "\n",
        "* Is it really needed if it is a non-GPU operation or say we are running on CPU (To be tested on CPU iteration)??*\n",
        "\n",
        "* For NLP the pytorch deals with batch size as second parameter, whilst for CNNs/Images usually batch size is first parameter\n",
        "\n",
        "As per the [documentation on RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN), if ```batch_first = True``` then the output will be provided as ```[batch_size, vocab, hidden_size]``` However this does not apply \n",
        "    1. to Embedding.\n",
        "    2. nn.Linear layer expects batch size as first positional argument\n",
        "\n",
        "```\n",
        "    torch.nn.RNN(*args, **kwargs)\n",
        "```\n",
        "\n",
        "Note from the documentation:\n",
        "\n",
        "Keep in mind that only a limited number of optimizers support **sparse gradients**: currently it’s optim.SGD (CUDA and CPU), optim.SparseAdam (CUDA and CPU) and optim.Adagrad (CPU)\n",
        "  - Sparse Gradients - implies network not receiving strong signals in backpropagation to tune the network, basically indicates vanishing gradient problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyt-roclvHF5"
      },
      "source": [
        "embedding = nn.Embedding(input_size, hidden_size).to(device)\n",
        "gru = nn.GRU(hidden_size, hidden_output).to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydLjlFBkNq4y",
        "outputId": "5c883ac2-88bd-43f8-b5aa-6c1d2be2b223"
      },
      "source": [
        "print(embedding)\n",
        "print(gru)\n",
        "print(input_tensor.shape)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(53793, 256)\n",
            "GRU(256, 128)\n",
            "torch.Size([14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUb_oQXYN-Pc",
        "outputId": "c1583579-97b7-4cca-ff06-9ab70f23b13b"
      },
      "source": [
        "## useless as does not have batch information, it will throw an error when passed to RNN/GRU cell \n",
        "# embedding_input = embedding(input_tensor) \n",
        "# print(embedding_input.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([14, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiVfyFBYRxh_"
      },
      "source": [
        "# Faking Batch using View/Squeeze\n",
        "\n",
        "### Difference between View and Squeeze\n",
        "1. when Dimensionality unknown use Unsequeze - takes a single dimension - so to add one dimension at a given position\n",
        "2. View needs is a view created on original tensor with almost equivalen of reshape operation. View avoids data copying of underlying tensor\n",
        "\n",
        "All [View ops](https://pytorch.org/docs/stable/tensor_view.html) in PyTorch are follows of not copying the data, so reshape, unsqueeze, view all are view ops. Some view operations do have special cases where they may return non-contigious tensor which upon calling ```.contigious()``` would return a contigious\n",
        "\n",
        "[Contingious Tensor](https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107) has certain behaviour on copying the data and performance. How a tensor is laid out in memory and reading performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iyYHWvuvd0V",
        "outputId": "0ae0ab89-c337-4bc2-f373-ebca11e2b741"
      },
      "source": [
        "embedding_input = embedding(input_tensor.view(-1, 1))\n",
        "embedding_input.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14, 1, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKYCOPgnXjYc"
      },
      "source": [
        "## Understanding the inputs:\n",
        "\n",
        "1. embedding input - of dimensions (embedding_size, batch, hidden_size) as declared in embedding class initialization.\n",
        "2. Hidden vector - basically previous output\n",
        "uni directional LSTM **if** it is 2 layers and bi-directional then the vector should be of dimensions ```(4,1, hidden_output)``` here it will be ```(1, 1, hidden_output)```\n",
        "\n",
        "  ```(1*num_layers, batch_size, hidden_ouput)```        or \n",
        "  ```(2*num_layers, batch_size, hidden_ouput)```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VvqnY56vtTD"
      },
      "source": [
        "prv_out_put = torch.zeros(1,1,hidden_output, device=device)\n",
        "output, hidden = gru(embedding_input, prv_out_put)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcCR4sIHwNvc",
        "outputId": "4e3b59e5-0be8-410c-cab2-213c816d82f2"
      },
      "source": [
        "prv_out_put.shape, output.shape, hidden.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 128]), torch.Size([14, 1, 128]), torch.Size([1, 1, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEzjz7bjbvLP"
      },
      "source": [
        "## A word about storing Encoder ouputs\n",
        "\n",
        "1. we are passing the tokens ```MAX_LENGTH``` and each output to GRU layer needs to be saved in order to calculate Attention Matrix. - keep clam and storing on :)\n",
        "\n",
        "**** Dimensions *****\n",
        "\n",
        "single output is (1, batch_size, hidden_ouput)\n",
        "So the tensor requires for storing is (MAX_LENGTH, hidden_output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TznIohRVeI4T",
        "outputId": "a88acbe5-89a3-41ef-d165-fdd758e0742d"
      },
      "source": [
        "input_tensor.shape, output.shape, hidden.shape, input_tensor.size()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([14]),\n",
              " torch.Size([14, 1, 128]),\n",
              " torch.Size([1, 1, 128]),\n",
              " torch.Size([14]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "cVAQ9fWtwjK-",
        "outputId": "fc541a89-6a6f-4084-8773-ca8fff1eb5b1"
      },
      "source": [
        "encoder_outputs = torch.zeros(MAX_LENGTH, hidden_output, device=device)\n",
        "\n",
        "## for each word in input tensor   GRU(256, 128)\n",
        "for i in range(input_tensor.size()[0]):\n",
        "  embedding_in = embedding(input_tensor[i])\n",
        "  print(\"Embedding\", embedding_in.shape)\n",
        "  output, hidden_ou = gru(embedding_in, hidden)\n",
        "  print(\"Output : \", output.shape, \"Hidden : \", hidden_ou.shape )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding torch.Size([256])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8e3a00cacf04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0membedding_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Embedding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_ou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Hidden : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_ou\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysOS_wE86BFR"
      },
      "source": [
        "### Above Error are due to embedding size is [256], what is expected is ```[1, 1, 256]``` where ```1``` - is for ```word```, ```1``` - ```batch``` and ```256``` is ```embedding size```\n",
        "\n",
        "1. convert the embedding to 1, 256\n",
        "2. When not using ```nn.Module```  the loop is taken care ..as told by *the Oracle* -> Need to find out **why**\n",
        "3. Why does all encoder_outputs need ```+``` ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSWNMO0R4ehe",
        "outputId": "5c56ccb0-a03d-4f38-f59b-12fcbded10a4"
      },
      "source": [
        "encoder_outputs = torch.zeros(MAX_LENGTH, hidden_output, device=device)\n",
        "hidden_in = torch.zeros(1, 1, hidden_output, device = device)\n",
        "## for each word in input tensor   GRU(256, 128)\n",
        "print(\" loop for : \",input_tensor.size()[0])\n",
        "for i in range(input_tensor.size()[0]):\n",
        "  # print(\"input_tensor shape : \", input_tensor[i])\n",
        "  embedding_in = embedding(input_tensor[i].view(-1, 1))\n",
        "  # print(\"Embedding\", embedding_in.shape, \" hidden output: \", hidden_in.shape)\n",
        "  output, hidden_ou = gru(embedding_in, hidden_in)\n",
        "  # print(\"Output : \", output.shape, \" Hidden gru : \", hidden_ou.shape, \"output [0, 0] : \", output[0, 0].shape)\n",
        "  encoder_outputs[i] += output[0, 0]\n",
        "\n",
        "print(\"encoder_outputs : \", encoder_outputs.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " loop for :  14\n",
            "encoder_outputs :  torch.Size([20, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPYL55V-Id7R"
      },
      "source": [
        "# Decoder with Attention\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX8loAnyBj1u",
        "outputId": "018cabf1-f354-46df-9036-2d1090b0a38b"
      },
      "source": [
        "decoder_input = torch.tensor([[SOS_token]] , device = device)\n",
        "decoder_hidden = hidden_in\n",
        "decoder_input.shape, decoder_hidden.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1]), torch.Size([1, 1, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BwdPCk0JuH1",
        "outputId": "d5bbbacf-afa7-4bdf-d9ae-fc4f14fff2d5"
      },
      "source": [
        "output_size = output_sent.n_wrds\n",
        "embedding_out = nn.Embedding(output_size, hidden_output).to(device)\n",
        "embedded_out = embedding_out(decoder_input)\n",
        "embedded_out.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niWsaSJeNzfM"
      },
      "source": [
        "## Attention Layer  Def\n",
        "\n",
        "1. concatinating output of encoder and output of decoder will be passed through fully connected layer\n",
        "So the **Dimensions would be** \n",
        "  - 2*hidden_ouput\n",
        "  - n_wrds for input sentence, which is 14 or could be upto max_length\n",
        "2. Then Matrix multiplication in batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cah5l5bHKK7y"
      },
      "source": [
        "attn_layer = nn.Linear(2*hidden_output, MAX_LENGTH).to(device)\n",
        "attn_lyr_wgts = attn_layer(torch.cat((embedded_out[0], decoder_hidden[0]), 1))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8zUnYyBVEP3",
        "outputId": "5e7c43c3-331f-483d-fb33-82cba4571e3e"
      },
      "source": [
        "attn_lyr_wgts.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uswm8BSeY9Dt",
        "outputId": "5dffc2d2-df69-4ff2-9da1-b461203b0247"
      },
      "source": [
        "hidden_output, embedded_out[0].shape, decoder_hidden[0].shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, torch.Size([1, 128]), torch.Size([1, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od3BDijoZzzn",
        "outputId": "3372dcdc-66cf-4a79-df22-5c9593ece87c"
      },
      "source": [
        "(torch.cat((embedded_out[0], decoder_hidden[0]), 1)).shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTofS4MMZD2_",
        "outputId": "51a1a086-0bae-4eb2-9bec-6d405af75306"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "attn_layer = nn.Linear(2*hidden_output, MAX_LENGTH).to(device)\n",
        "attn_lyr_wgts = attn_layer(torch.cat((embedded_out[0], decoder_hidden[0]), 1))\n",
        "attn_lyr_sftmx = F.softmax(attn_lyr_wgts, dim=1)\n",
        "print(attn_lyr_sftmx.shape)\n",
        "attn_lyr_sftmx"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0488, 0.0541, 0.0854, 0.0514, 0.0484, 0.0267, 0.0236, 0.0566, 0.0498,\n",
              "         0.0355, 0.0231, 0.0589, 0.0475, 0.0688, 0.0403, 0.0749, 0.0581, 0.0563,\n",
              "         0.0467, 0.0450]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvBFPuuIZa2L",
        "outputId": "802e0f17-4be2-4e19-92a3-bb08480ecbeb"
      },
      "source": [
        " attn_lyr_wgts.shape, attn_lyr_wgts.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 20]), torch.Size([1, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTehodwi4orq",
        "outputId": "b9660641-ddeb-4f99-ec2d-f42fea5da9e0"
      },
      "source": [
        "### softmax probability should 0?\n",
        "\n",
        "sum([0.0488, 0.0541, 0.0854, 0.0514, 0.0484, 0.0267, 0.0236, 0.0566, 0.0498, 0.0355, 0.0231, 0.0589, 0.0475, 0.0688, 0.0403, 0.0749, 0.0581, 0.0563, 0.0467, 0.0450])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9998999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DouiSV-tVI7v",
        "outputId": "5456351b-8b64-4532-dfa3-3a57c67dedf4"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "attn_layer = nn.Linear(2*hidden_output, MAX_LENGTH).to(device)\n",
        "attn_lyr_wgts = attn_layer(torch.cat((embedded_out[0], decoder_hidden[0]), 1))\n",
        "attn_lyr_sftmx = F.softmax(attn_lyr_wgts, dim=1)\n",
        "print(attn_lyr_sftmx.shape)\n",
        "attn_lyr_sftmx"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0518, 0.0199, 0.0714, 0.0186, 0.0421, 0.0380, 0.0474, 0.0383, 0.0322,\n",
              "         0.0711, 0.0596, 0.0356, 0.0625, 0.0548, 0.0690, 0.0629, 0.0580, 0.0971,\n",
              "         0.0346, 0.0351]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvxJR1ShVuml",
        "outputId": "c59b091e-1b9e-4431-beff-2c8c33da56ce"
      },
      "source": [
        "attn_lyr_sftmx.shape, encoder_outputs.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 20]), torch.Size([20, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1IUJN65X6Cg"
      },
      "source": [
        "> ### Will throw an error crying for b, B stand for batch in Bmm if I dont add the batch, batch indicates first argument here - different from RNN cells...\n",
        "\n",
        "\n",
        "> ### torch.bmm(attn_lyr_sftmx, encoder_outputs) using unsqueeze and view - why cause I can! but it shows how combersome it\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu0SebgaWGQB",
        "outputId": "ec806dcb-819b-4163-a888-8ccef9b7adac"
      },
      "source": [
        "\n",
        "attn_lyr_sftmx.unsqueeze(0).shape,  encoder_outputs.view(-1, 20 ,128).shape,  encoder_outputs.unsqueeze(0).shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 20]), torch.Size([1, 20, 128]), torch.Size([1, 20, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y_pVhX9WTEV",
        "outputId": "8e7b55cb-df8b-4487-f6ea-18701dca1c8c"
      },
      "source": [
        "bmm = torch.bmm(attn_lyr_sftmx.unsqueeze(0), encoder_outputs.unsqueeze(0) )\n",
        "bmm.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFu7JjXjbFzY"
      },
      "source": [
        "### Input to GRU Layer for encoder is \n",
        " - s1 - concating attention and zero input tensor\n",
        " - c1 - atten applied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv7qJkDQdyXM",
        "outputId": "4823841c-dc5f-49ad-f0db-035af65214eb"
      },
      "source": [
        "embedded_out.shape, bmm.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 128]), torch.Size([1, 1, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdKFgpwKX03n",
        "outputId": "c3f80cf2-06f9-448f-a224-259deaaa47b7"
      },
      "source": [
        "in_gru_layer = nn.Linear(128 * 2, 256).to(device)\n",
        "in_gru_lyr = in_gru_layer(torch.cat((embedded_out[0], bmm[0]), 1))\n",
        "print(in_gru_lyr.shape)\n",
        "in_gru_lyr = in_gru_lyr.unsqueeze(0)\n",
        "in_gru_lyr.shape, decoder_hidden.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]), torch.Size([1, 1, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb39XuyLe8AQ",
        "outputId": "b9d21416-f9b5-4d96-d21d-1bd96467ce33"
      },
      "source": [
        "decdr_gru = nn.GRU(256, 256).to(device)\n",
        "output, decoder_hidden = decdr_gru(decoder_hidden, in_gru_lyr)\n",
        "print(\" output : \", output.shape, \"decoder_hidden : \", decoder_hidden.shape)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " output :  torch.Size([1, 1, 256]) decoder_hidden :  torch.Size([1, 1, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MELS41HfI1N",
        "outputId": "521aa223-5eca-4a14-a0e6-21f79100d806"
      },
      "source": [
        "output_word_layer = nn.Linear(256, output_sent.n_wrds).to(device)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim=1)\n",
        "output.shape, output, output.data.topk(1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 49147]),\n",
              " tensor([[2.2734e-05, 2.4490e-05, 2.0388e-05,  ..., 1.8827e-05, 2.0228e-05,\n",
              "          1.8521e-05]], grad_fn=<SoftmaxBackward0>),\n",
              " torch.return_types.topk(values=tensor([[3.3170e-05]]), indices=tensor([[33715]])))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOTA7y4y9HHt",
        "outputId": "0d0048cd-bcbc-4cb7-b404-18dd45082309"
      },
      "source": [
        "print(type(output.data.topk(1)))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.return_types.topk'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcLJJly89Ws1",
        "outputId": "eabef118-81c5-4109-cdcc-0a84c4b3cae4"
      },
      "source": [
        "# Printing top 10 words with probabilty \n",
        "topv, topi = output.data.topk(10)\n",
        "# print(topv.shape)\n",
        "# print(topi.shape)\n",
        "for idx, i in enumerate(topi[0]):\n",
        "  wrd = output_sent.index2word[i.item()]\n",
        "  print('word : ', wrd, ' probability : ', topv[0][idx])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word :  islanding  probability :  tensor(3.3170e-05)\n",
            "word :  logx  probability :  tensor(3.2584e-05)\n",
            "word :  meadowbrook  probability :  tensor(3.2089e-05)\n",
            "word :  cyberpunk  probability :  tensor(3.1560e-05)\n",
            "word :  audrey  probability :  tensor(3.1240e-05)\n",
            "word :  enviromental  probability :  tensor(3.0541e-05)\n",
            "word :  myregistry  probability :  tensor(3.0099e-05)\n",
            "word :  trams  probability :  tensor(3.0059e-05)\n",
            "word :  vectors  probability :  tensor(2.9853e-05)\n",
            "word :  prelude  probability :  tensor(2.9403e-05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taaajZDC72Ld",
        "outputId": "ea2ea97f-c2a4-43df-cd41-6d55e25a7c72"
      },
      "source": [
        "topv, topi = output.data.topk(1)\n",
        "print(topv.shape)\n",
        "print(topi.shape)\n",
        "for i in topi:\n",
        "  wrd = output_sent.index2word[i.item()]\n",
        "  print(wrd)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1])\n",
            "torch.Size([1, 1])\n",
            "islanding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94unc_Iw8hdo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}